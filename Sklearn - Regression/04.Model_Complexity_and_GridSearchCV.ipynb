{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter selection, Validation, and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most models have parameters that influence how complex a model they can learn. Remember using `KNeighborsRegressor`.\n",
    "If we change the number of neighbors we consider, we get a smoother and smoother prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Over-fitting, and Under-fitting\n",
    "\n",
    "Unfortunately, there is no general rule how to find the sweet spot, and so machine learning practitioners have to find the best trade-off of model-complexity and generalization by trying several hyperparameter settings. Hyperparameters are the internal knobs or tuning parameters of a machine learning algorithm (in contrast to model parameters that the algorithm learns from the training data -- for example, the weight coefficients of a linear regression model); the number of *k* in K-nearest neighbors is such a hyperparameter.\n",
    "\n",
    "Most commonly this \"hyperparameter tuning\" is done using a brute force search, for example over multiple values of ``n_neighbors``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, average score: 0.451377\n",
      "n_neighbors: 3, average score: 0.705597\n",
      "n_neighbors: 5, average score: 0.704576\n",
      "n_neighbors: 10, average score: 0.731733\n",
      "n_neighbors: 20, average score: 0.588740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KindYAK\\Anaconda3\\envs\\def\\lib\\site-packages\\sklearn\\model_selection\\_split.py:426: FutureWarning: You should specify a value for 'n_splits' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# generate toy dataset:\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "cv = KFold(shuffle=True)\n",
    "\n",
    "# for each parameter setting do cross-validation:\n",
    "for n_neighbors in [1, 3, 5, 10, 20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print(\"n_neighbors: %d, average score: %f\" % (n_neighbors, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function in scikit-learn, called ``validation_plot`` to reproduce the cartoon figure above. It plots one parameter, such as the number of neighbors, against training and validation error (using cross-validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1, 3, 5, 10, 20, 50]\n",
    "train_scores, test_scores = validation_curve(KNeighborsRegressor(), X, y, param_name=\"n_neighbors\",\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_scores.mean(axis=1), label=\"train accuracy\")\n",
    "plt.plot(n_neighbors, test_scores.mean(axis=1), label=\"test accuracy\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.xlim([50, 0])\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple parameters are important, like the parameters ``C`` and ``gamma`` in an ``SVM`` (more about that later), all possible combinations are tried:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, average score: -0.137492\n",
      "C: 0.001000, gamma: 0.010000, average score: -0.050958\n",
      "C: 0.001000, gamma: 0.100000, average score: -0.044582\n",
      "C: 0.001000, gamma: 1.000000, average score: -0.176818\n",
      "C: 0.010000, gamma: 0.001000, average score: -0.115822\n",
      "C: 0.010000, gamma: 0.010000, average score: -0.065704\n",
      "C: 0.010000, gamma: 0.100000, average score: 0.091398\n",
      "C: 0.010000, gamma: 1.000000, average score: 0.058601\n",
      "C: 0.100000, gamma: 0.001000, average score: -0.006215\n",
      "C: 0.100000, gamma: 0.010000, average score: 0.187019\n",
      "C: 0.100000, gamma: 0.100000, average score: 0.448108\n",
      "C: 0.100000, gamma: 1.000000, average score: 0.498500\n",
      "C: 1.000000, gamma: 0.001000, average score: 0.158360\n",
      "C: 1.000000, gamma: 0.010000, average score: 0.575621\n",
      "C: 1.000000, gamma: 0.100000, average score: 0.576924\n",
      "C: 1.000000, gamma: 1.000000, average score: 0.716055\n",
      "C: 10.000000, gamma: 0.001000, average score: 0.559661\n",
      "C: 10.000000, gamma: 0.010000, average score: 0.622085\n",
      "C: 10.000000, gamma: 0.100000, average score: 0.645632\n",
      "C: 10.000000, gamma: 1.000000, average score: 0.758696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# each parameter setting do cross-validation:\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print(\"C: %f, gamma: %f, average score: %f\" % (C, gamma, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is such a very common pattern, there is a built-in class for this in scikit-learn, ``GridSearchCV``. ``GridSearchCV`` takes a dictionary that describes the parameters that should be tried and a model to train.\n",
    "\n",
    "The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested.\n",
    "\n",
    "To inspect training score on the different folds, the parameter ``return_train_score`` is set to ``True``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv, verbose=3, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a *meta-estimator*. It takes an estimator like SVR above, and creates a new estimator, that behaves exactly the same - in this case, like a regressor.\n",
    "So we can call ``fit`` on it, to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] . C=0.001, gamma=0.001, score=-0.02517722849580606, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=-0.027324221720739898, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=-0.0014955469997441906, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] .. C=0.001, gamma=0.01, score=-0.02308945442634358, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] .. C=0.001, gamma=0.01, score=-0.02498098684598893, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] . C=0.001, gamma=0.01, score=0.0006034362359643719, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .. C=0.001, gamma=0.1, score=-0.014065288336936543, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .. C=0.001, gamma=0.1, score=-0.014995007557014217, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ... C=0.001, gamma=0.1, score=0.009665916038985145, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] .... C=0.001, gamma=1, score=-0.015325270542456249, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] .... C=0.001, gamma=1, score=-0.016911313745984202, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ..... C=0.001, gamma=1, score=0.008124708664994928, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] . C=0.01, gamma=0.001, score=-0.022871062356535576, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] . C=0.01, gamma=0.001, score=-0.024734224866717502, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] . C=0.01, gamma=0.001, score=0.0008153831193199457, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .. C=0.01, gamma=0.01, score=-0.002173331069651674, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] . C=0.01, gamma=0.01, score=-0.0025469508419784237, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ... C=0.01, gamma=0.01, score=0.020873294530782238, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ..... C=0.01, gamma=0.1, score=0.08766704210671838, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ..... C=0.01, gamma=0.1, score=0.08050325511338674, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ..... C=0.01, gamma=0.1, score=0.10524925171238919, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ....... C=0.01, gamma=1, score=0.07562334648175972, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ....... C=0.01, gamma=1, score=0.06983600372686005, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ....... C=0.01, gamma=1, score=0.09073421533430037, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV]  C=0.1, gamma=0.001, score=-2.7988232972564475e-05, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] . C=0.1, gamma=0.001, score=-0.0005122560055967895, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ... C=0.1, gamma=0.001, score=0.022856625056515978, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ..... C=0.1, gamma=0.01, score=0.17583609265206634, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ..... C=0.1, gamma=0.01, score=0.16230226037521323, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ...... C=0.1, gamma=0.01, score=0.1830543618456696, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.5394950321190106, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.4992460144428654, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ......... C=0.1, gamma=0.1, score=0.51786485044339, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.5271229407881414, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.4874554294284624, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.4829976880543394, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ...... C=1, gamma=0.001, score=0.19111533441820416, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ...... C=1, gamma=0.001, score=0.17539831693083519, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ...... C=1, gamma=0.001, score=0.19526221055152793, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.6077347784865729, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.5629422706375664, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.6188924599682218, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.6942194773505785, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.6674741013604408, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.6537234642120293, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.7124052564116046, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.7393461182864849, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.7134121343400173, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.6098692145792857, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.5567202261127702, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.6106208474438513, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.6258608201856593, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.6220397215873005, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.6449373657763533, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ......... C=10, gamma=0.1, score=0.683053347473438, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ......... C=10, gamma=0.1, score=0.673886689076401, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.6353937175447446, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.7578787461607204, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.7855814981868086, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.7808174937512518, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Users\\KindYAK\\Anaconda3\\envs\\def\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "  gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ``fit`` does is a bit more involved then what we did above. First, it runs the same loop with cross-validation, to find the best parameter combination.\n",
    "Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as with all models, we can use ``predict`` or ``score``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79762875, -1.74054091, -1.71412904, -1.72272347, -1.76880247,\n",
       "       -1.8527208 , -1.97255382, -2.12407501, -2.30087676, -2.49463429,\n",
       "       -2.695503  , -2.89262935, -3.07474705, -3.23082299, -3.35071314,\n",
       "       -3.42578612, -3.44947391, -3.41771237, -3.32924127, -3.18574205,\n",
       "       -2.9918017 , -2.75470244, -2.48404785, -2.19124658, -1.88888388,\n",
       "       -1.59001819, -1.30744475, -1.05297034, -0.8367425 , -0.66667333,\n",
       "       -0.54799235, -0.4829551 , -0.4707249 , -0.50743515, -0.58642852,\n",
       "       -0.69865919, -0.83323456, -0.97806438, -1.12057877, -1.24847261,\n",
       "       -1.35043139, -1.41679516, -1.44012026, -1.41560488, -1.3413525 ,\n",
       "       -1.21845724, -1.05090633, -0.84530623, -0.61045003, -0.35675398,\n",
       "       -0.09559933,  0.16137852,  0.40300817,  0.61926205,  0.80185531,\n",
       "        0.94472644,  1.04437082,  1.10000798,  1.11357463,  1.08954695,\n",
       "        1.03460678,  0.95717608,  0.86685224,  0.7737823 ,  0.68801751,\n",
       "        0.61888941,  0.57444669,  0.56098656,  0.58270777,  0.64150352,\n",
       "        0.73690334,  0.86616306,  1.02449275,  1.20540425,  1.40115266,\n",
       "        1.60324152,  1.80295801,  1.99190412,  2.16249073,  2.3083654 ,\n",
       "        2.42474939,  2.50866621,  2.55905134,  2.57674055,  2.56434191,\n",
       "        2.52600389,  2.46709789,  2.39383845,  2.31286721,  2.23082834,\n",
       "        2.15396216,  2.0877418 ,  2.03657355,  2.00357681,  1.99045342,\n",
       "        1.99745004,  2.02341108,  2.06591373,  2.12147209,  2.18579347])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the best parameters found by ``GridSearchCV`` in the ``best_params_`` attribute, and the best score in the ``best_score_`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7745904410342048\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you can investigate the performance and much more for each set of parameter values by accessing the `cv_results_` attributes. The `cv_results_` attribute is a dictionary where each key is a string and each value is array. It can therefore be used to make a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_gamma', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'mean_train_score', 'std_train_score'])\n"
     ]
    }
   ],
   "source": [
    "print(grid.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.001}</td>\n",
       "      <td>-0.025177</td>\n",
       "      <td>-0.027324</td>\n",
       "      <td>-0.001496</td>\n",
       "      <td>-0.018071</td>\n",
       "      <td>0.011666</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.002102</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>-0.000682</td>\n",
       "      <td>0.001004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.01}</td>\n",
       "      <td>-0.023089</td>\n",
       "      <td>-0.024981</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>-0.015895</td>\n",
       "      <td>0.011605</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.1}</td>\n",
       "      <td>-0.014065</td>\n",
       "      <td>-0.014995</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>-0.006541</td>\n",
       "      <td>0.011380</td>\n",
       "      <td>16</td>\n",
       "      <td>0.007694</td>\n",
       "      <td>0.010993</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>0.010184</td>\n",
       "      <td>0.001796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 1}</td>\n",
       "      <td>-0.015325</td>\n",
       "      <td>-0.016911</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>-0.008110</td>\n",
       "      <td>0.011412</td>\n",
       "      <td>17</td>\n",
       "      <td>0.006788</td>\n",
       "      <td>0.009948</td>\n",
       "      <td>0.010758</td>\n",
       "      <td>0.009164</td>\n",
       "      <td>0.001713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.001}</td>\n",
       "      <td>-0.022871</td>\n",
       "      <td>-0.024734</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>-0.015669</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.001161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.000665      0.000470         0.000665        0.000470   0.001   \n",
       "1       0.000332      0.000470         0.000665        0.000470   0.001   \n",
       "2       0.000331      0.000468         0.000662        0.000468   0.001   \n",
       "3       0.000343      0.000486         0.000664        0.000469   0.001   \n",
       "4       0.000000      0.000000         0.000677        0.000479    0.01   \n",
       "\n",
       "  param_gamma                        params  split0_test_score  \\\n",
       "0       0.001  {'C': 0.001, 'gamma': 0.001}          -0.025177   \n",
       "1        0.01   {'C': 0.001, 'gamma': 0.01}          -0.023089   \n",
       "2         0.1    {'C': 0.001, 'gamma': 0.1}          -0.014065   \n",
       "3           1      {'C': 0.001, 'gamma': 1}          -0.015325   \n",
       "4       0.001   {'C': 0.01, 'gamma': 0.001}          -0.022871   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0          -0.027324          -0.001496        -0.018071        0.011666   \n",
       "1          -0.024981           0.000603        -0.015895        0.011605   \n",
       "2          -0.014995           0.009666        -0.006541        0.011380   \n",
       "3          -0.016911           0.008125        -0.008110        0.011412   \n",
       "4          -0.024734           0.000815        -0.015669        0.011594   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0               20           -0.002102            0.000001   \n",
       "1               19           -0.000302            0.002037   \n",
       "2               16            0.007694            0.010993   \n",
       "3               17            0.006788            0.009948   \n",
       "4               18           -0.000123            0.002242   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.000054         -0.000682         0.001004  \n",
       "1            0.002212          0.001315         0.001146  \n",
       "2            0.011864          0.010184         0.001796  \n",
       "3            0.010758          0.009164         0.001713  \n",
       "4            0.002427          0.001515         0.001161  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.774590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.721628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.672030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.664301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.630895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_gamma  mean_test_score\n",
       "19      10           1         0.774590\n",
       "15       1           1         0.721628\n",
       "14       1         0.1         0.672030\n",
       "18      10         0.1         0.664301\n",
       "17      10        0.01         0.630895"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_tiny = cv_results[['param_C', 'param_gamma', 'mean_test_score']]\n",
    "cv_results_tiny.sort_values(by='mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with using this score for evaluation, however. You might be making what is called a multiple hypothesis testing error. If you try very many parameter settings, some of them will work better just by chance, and the score that you obtained might not reflect how your model would perform on new unseen data.\n",
    "Therefore, it is good to split off a separate test-set before performing grid-search. This pattern can be seen as a training-validation-test split, and is common in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this very easily by splitting of some test data using ``train_test_split``, training ``GridSearchCV`` on the training set, and applying the ``score`` method to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KindYAK\\Anaconda3\\envs\\def\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the parameters that were selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=-0.006250318151439949, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] . C=0.001, gamma=0.01, score=-0.003444992272036762, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .. C=0.001, gamma=0.1, score=0.0069106995753801526, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ..... C=0.001, gamma=1, score=0.002517682720296288, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] . C=0.01, gamma=0.001, score=-0.003098154945419651, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .... C=0.01, gamma=0.01, score=0.02371574189949055, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ..... C=0.01, gamma=0.1, score=0.12178063829361374, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ....... C=0.01, gamma=1, score=0.08496909761264737, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ... C=0.1, gamma=0.001, score=0.026934580083858628, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ..... C=0.1, gamma=0.01, score=0.23772017193141204, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.5783613006382644, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ........ C=0.1, gamma=1, score=0.43349018272906514, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....... C=1, gamma=0.001, score=0.2598705918007943, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.7489362718729025, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.7985698831911917, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.7782103978871786, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ....... C=10, gamma=0.001, score=0.760613367386165, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.7988206334834607, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.7775924217605853, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ........... C=10, gamma=1, score=0.886126930517208, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "single_split_cv = ShuffleSplit(n_splits=1)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=single_split_cv, verbose=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much faster, but might result in worse hyperparameters and therefore worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KindYAK\\Anaconda3\\envs\\def\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(SVR(), param_grid=param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
